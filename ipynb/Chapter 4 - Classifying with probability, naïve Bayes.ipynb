{
 "metadata": {
  "name": "",
  "signature": "sha256:ff422e10faf477dd251e1432a4c8923b88ea99f15c64892a0c018889388534f6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4.- Classifying with probability theory: na\u00efve Bayes\n",
      "====================================================\n",
      "\n",
      "In summary, we want to know the best guess of a class for a given sample and, in addition, a probability estimate to that best guess.\n",
      "\n",
      "4.1.- Classifying with Bayesian decision theory\n",
      "-----------------------------------------------\n",
      "\n",
      "4.2.- Conditional probability\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "Bayes rule used to compute probabilities\n",
      "\n",
      "$$\n",
      "p(A|B) = \\frac{p(B|A) \\cdot p(A)}{p(B)}\n",
      "$$\n",
      "\n",
      "4.3- Classifying with conditional probabilities\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "4.4.- Document classification with Bayes\n",
      "----------------------------------------\n",
      "\n",
      "Words are used as features in a document, which we intend to classify\n",
      "\n",
      "4.5.- Classifying text with Python\n",
      "----------------------------------\n",
      "\n",
      "The purpose is to classify a text as *abusive* (``1``) or not (``0``)\n",
      "\n",
      "###4.5.1.- Prepare: making word vectors from text###\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_data_set():\n",
      "    \n",
      "    sentences = [ 'my dog has flea problems help please',\n",
      "                  'maybe not take him to dog park stupid',\n",
      "                  'my dalmation is so cute I love him',\n",
      "                  'stop posting sutpid worthless garbage',\n",
      "                  'mr licks ate my steak how to stop him',\n",
      "                  'quit buying worthless dog food stupid' ]\n",
      "    \n",
      "    posting_list = [ s.split() for s in sentences ]\n",
      "    posting_class = [0,1,0,1,0,1]   # 1 means abusive, 0 does not\n",
      "    \n",
      "    return (posting_list, posting_class)\n",
      "\n",
      "def create_vocab_list(data_set):\n",
      "    \"\"\"\n",
      "    Creates a list of words (unique) that are present in the document\n",
      "    \n",
      "    >>> create_vocab_list([\"I am a dog not a cat\".split(), \\\n",
      "                           \"I am a jiraffe\".split()])\n",
      "    ['a', 'not', 'I', 'jiraffe', 'am', 'dog', 'cat']\n",
      "    \"\"\"\n",
      "    \n",
      "    vocab_set = set([])\n",
      "    \n",
      "    for document in data_set:\n",
      "        vocab_set |= set(document)\n",
      "        \n",
      "    return list(vocab_set)\n",
      "        \n",
      "def verify_document_words(document, vocabulary_list):\n",
      "    \"\"\"\n",
      "    This method takes the words present in the document and checks if each word\n",
      "    is listed in the vocabulary list, it returns a vector of the same lenght\n",
      "    than vocabulary list in which each position (i.e. word) will have a 1 or 0\n",
      "    depending on wether the word is in document (1) or not (0).\n",
      "    \n",
      "    >>> verify_document_words( \"I am a dog not a cat\".split(),[\"dog\", \"jiraffe\", \"mouse\", \"cat\", \"moose\"])\n",
      "    [1, 0, 0, 1, 0]\n",
      "    \"\"\"\n",
      "    \n",
      "    return [ 1 if w in document else 0 for w in vocabulary_list ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verify_document_words( \"I am a dog not a cat\".split(),[\"dog\", \"jiraffe\", \"mouse\", \"cat\", \"moose\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "[1, 0, 0, 1, 0]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_vocab_list([\"I am a dog not a cat\".split(), \\\n",
      "                           \"I am a jiraffe\".split()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "['a', 'not', 'I', 'jiraffe', 'am', 'dog', 'cat']"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_of_posts, list_of_classes = create_data_set()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocabulary_list = create_vocab_list( list_of_posts )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocabulary_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['cute',\n",
        " 'love',\n",
        " 'help',\n",
        " 'garbage',\n",
        " 'I',\n",
        " 'problems',\n",
        " 'is',\n",
        " 'park',\n",
        " 'steak',\n",
        " 'stop',\n",
        " 'flea',\n",
        " 'dalmation',\n",
        " 'ate',\n",
        " 'food',\n",
        " 'not',\n",
        " 'him',\n",
        " 'buying',\n",
        " 'posting',\n",
        " 'quit',\n",
        " 'worthless',\n",
        " 'licks',\n",
        " 'how',\n",
        " 'maybe',\n",
        " 'please',\n",
        " 'dog',\n",
        " 'to',\n",
        " 'stupid',\n",
        " 'so',\n",
        " 'take',\n",
        " 'mr',\n",
        " 'sutpid',\n",
        " 'has',\n",
        " 'my']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verify_document_words(list_of_posts[0], vocabulary_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verify_document_words(list_of_posts[1], vocabulary_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###4.5.2.- Train: Calculating probabilities from word vectors###\n",
      "\n",
      "Using the notation of $\\bf{w}$ for word and $c_i$ for the $i$-th class, we can formulate the statement *probability to be of class $i$-th given the fact that the list/vector/set of words ${\\bf w}$ is present* using Bayes:\n",
      "\n",
      "$$\n",
      "p(c_i|{\\bf w}) = \\frac{p({\\bf w}|c_i) \\cdot p({\\bf w})}{p(c_i)}\n",
      "$$\n",
      "\n",
      "where:\n",
      "- $p{c_i}$ is the probability to find the $i$-th class in the dataset. In our class, if we want to find the probability for the class *abusive* we note that it appears 3 times in our data set of 6 elements. Therefore $p(abusive) = 3/6 = 0.5$\n",
      "- $p({\\bf w}|c_i)$ is the probability of finding the set of words ${\\bf w}$ given that the document is of $i$-th class. To compute this term we need the assumption that all the words occur *independently* (hence *na\u00efve Bayes*). Under this assumption, we can compute this probability as:\n",
      "\n",
      "$$\n",
      "p({\\bf w}|c_i) = \\prod_{k=1}^N p(w_k | c_i) = p(w_1 | c_i) \\cdot p(w_2 | c_i)\\cdot \\ldots \\cdot p(w_N | c_i)\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}