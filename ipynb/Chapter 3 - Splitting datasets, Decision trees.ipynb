{
 "metadata": {
  "name": "",
  "signature": "sha256:46c841823b0154e4220c6b47bc25d4e7371a748b08a5a59028a37ef67456b1fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.- Splitting datasets one feature at a time: Decision trees\n",
      "============================================================\n",
      "\n",
      "\n",
      "3.1.- Tree construction\n",
      "-----------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###3.1.1.- Information gain (Entropy)###\n",
      "\n",
      "As defined in [Wikipedia](http://en.wikipedia.org/wiki/Entropy_(information_theory), Entropy is **a measure of uncertainty**. Entropy is larger as the source of information is also more random. The less random, the lower the Entropy.\n",
      "\n",
      "Assuming a dicrete random variable $X$ than has the following possible values: $$ {\u00a0x_1, x_2, ..., x_N }$$\n",
      "\n",
      "will have an Entropy ($H$):\n",
      "\n",
      "$$\n",
      "H = - \\sum_{i=1}^{N} p_i \\cdot \\log_2{p_i} \n",
      "$$\n",
      "\n",
      "where $p_i$ is the probability that the value $x_i$ of the random variable $X$ occurs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "# Method to compute the entropy of a dataset\n",
      "def entropy(data_set):\n",
      "    \"\"\"\n",
      "    We are assuming that data_set is a collection of samples,\n",
      "    and each samples has some features and a label in the last field\n",
      "    \n",
      "    >>> entropy( [[1],[0]] )   # Fair coinflip, maximum uncertainty\n",
      "    1.0\n",
      "    \n",
      "    >>> entropy( [[0],[0]] )   # Loaded coinflip, previsible outcome\n",
      "    0.0\n",
      "    \"\"\"\n",
      "    \n",
      "    n_entries = len(data_set)\n",
      "    \n",
      "    # Let's count the labels so that we can then measure its \n",
      "    # probability within the data_set\n",
      "    label_counts = {}\n",
      "    \n",
      "    for sample in data_set:\n",
      "        \n",
      "        current_label = sample[-1]\n",
      "        if current_label not in label_counts:\n",
      "            label_counts[current_label] = 0\n",
      "            \n",
      "        label_counts[current_label] += 1\n",
      "        \n",
      "    # Compute the Entropy (H)\n",
      "    H = 0\n",
      "    \n",
      "    for key, count in label_counts.iteritems():\n",
      "        p = float(count) / n_entries\n",
      "        \n",
      "        H -= p * math.log(p, 2)\n",
      "    \n",
      "    return(H)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_set = [[1,1,'yes'],[1,1,'yes'], [1,0,'no'], [0,1,'no'], [0,1,'no'] ]\n",
      "entropy(data_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "0.9709505944546686"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add a little bit of uncertainty in the data set\n",
      "data_set[0][-1] = 'maybe'\n",
      "entropy(data_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "1.3709505944546687"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Gini impurity** is the probability of choosing an item from the set and the probability of that item from being missclassified"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###3.1.2.- Splitting the data set###\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split(data_set, column, value):\n",
      "    \n",
      "    split_data_set = []\n",
      "    \n",
      "    for sample in data_set:\n",
      "        if sample[column] == value:\n",
      "            \n",
      "            reduced_sample = sample[:column]\n",
      "            reduced_sample.extend( sample[column+1:] )\n",
      "            \n",
      "            split_data_set.append(reduced_sample)\n",
      "            \n",
      "    return split_data_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Have a look at the data set\n",
      "data_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all the features whose first column (0) takes the value of 1\n",
      "split(data_set, 0, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all the features whose first column (0) takes the other possible\n",
      "# value (0)\n",
      "split(data_set, 0, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "[[1, 'no'], [1, 'no']]"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division   # To avoid rounding of integer division\n",
      "\n",
      "def choose_best_split(data_set):\n",
      "    \n",
      "    # Making the split will imply that we are going to reduce \n",
      "    # the number of features for the following splits\n",
      "    n_features = len(data_set[0]) - 1 \n",
      "    \n",
      "    # Some initializations\n",
      "    base_entropy = entropy( data_set )\n",
      "    best_info_gain = 0.0\n",
      "    best_feature = None\n",
      "    \n",
      "    # Loop over all the number of features\n",
      "    for i in range(n_features):\n",
      "        \n",
      "        # Build a list of unique values that the feature can take\n",
      "        feature_values = set( [ sample[i] for sample in data_set ] )\n",
      "        \n",
      "        # Calculate the entropy due to this split\n",
      "        new_entropy = 0.0\n",
      "        for value in feature_values:\n",
      "            sub_data_set = split(data_set, i, value)\n",
      "            \n",
      "            p = len(sub_data_set) / len(data_set)\n",
      "            new_entropy += p * entropy(sub_data_set)\n",
      "            \n",
      "        info_gain = base_entropy - new_entropy\n",
      "            \n",
      "        if info_gain > best_info_gain:\n",
      "            best_info_gain = info_gain\n",
      "            best_feature = i\n",
      "            \n",
      "    return best_feature\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "choose_best_split(data_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}